---
layout:     post
title:      Spring boot 集成 Thrift 和 Zookeeper 建立微服务
subtitle:   基于 Spring boot框架，使用 Thrift 通信实现微服务，并通过 Zookeeper 进行服务治理
date:       2017-10-27
author:     uncledrew
header-img: img/post-bg-re-vs-ng2.jpg
catalog: true
tags:
    - Spring boot
    - Thrift
    - Zookeeper
    - 微服务
    - 服务治理
---

> 纸上得来终觉浅，绝知此事要躬行。
>
> [我的博客](http://uncledrewzhu.github.io/)

# 技术简介

#### Spring boot

优势：
- 简化新项目的初始搭建和开发过程
- 内嵌 Tomcat，无需部署WAR包
- 简化 Maven 配置
- 简化复杂的 XML 文件配置
- 自动配置 Spring

所以使用轻量级的 Spring boot 构建微服务是基础，也可以说是它的先天优势。

#### Thrift
Thrift 是 Facebook 公布的一款可扩展的跨语言服务开发的软件框架。

下面是引用网上的一段解释：
> 什么是RPC框架?

> RPC全称为Remote Procedure Call,意为远程过程调用.

> 假设有两台服务器A,B.A服务器上部署着一个应用a,B服务器上部署着一个应用b,现在a希望能够调用b应用的某个函数(方法),
但是二者不在同一个进程内,不能直接调用,就需要通过网络传输,在AB服务器之间建一条网络传输通道,a把参数传过去,
b接收到参数调用自己的方法,得到结果,再通过网络传回给a,简单讲就是A通过网络来调用B的过程.这个过程要涉及的东西很多,
比如多线程,Socket,序列化反序列化,网络I/O,很复杂,于是牛掰的程序员把这些封装起来做成一套框架,供大家使用,就是RPC框架.

> thrift的跨语言特型

> thrift通过一个中间语言IDL(接口定义语言)来定义RPC的数据类型和接口,这些内容写在以.thrift结尾的文件中,
然后通过特殊的编译器来生成不同语言的代码,以满足不同需要的开发者,比如java开发者,就可以生成java代码,
c++开发者可以生成c++代码,生成的代码中不但包含目标语言的接口定义,方法,数据类型,还包含有RPC协议层和传输层的实现代码.

#### Zookeeper
ZooKeeper 是一个分布式的，开放源码的分布式应用程序协调服务。

ZooKeeper 封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。

ZooKeeper 主要提供的功能：
- 配置维护
- 域名服务
- 分布式同步
- 组服务等

这里，我们是通过 Zookeeper 进行服务注册、服务发现和服务治理。

如图：
![](http://oxy6ml8al.bkt.clouddn.com/microservice-zookeeper.jpg)

本地如果想要搭建一个 Zookeeper 服务，可以使用 Docker 快速启动。我用的是 [wurstmeister/zookeeper](https://hub.docker.com/r/wurstmeister/zookeeper/) 这个镜像。

# 微服务案例
后端应用在 filter 中通过 kafka 生产者模式记录 http 报文日志，用于行为分析。

#### 使用 Thrift 定义接口协议
1.定义接口协议文件 `KafkaProducerService.thrift`

 ```
 namespace java kafka.producer.service
 
 struct MessageSendBean {
   1: string topic
   2: string message
 }
  
 service KafkaProducerService {
   void sendMessageToKafka(1:MessageSendBean messageSendBean)
 }
 ```
 
2.终端进入文件所在目录,执行命令:
 
 ```
 thrift -r -gen java KafkaProducerService.thrift
```

会生成一个 gen-java 的目录，里面有 `MessageSendBean.java` 和 `KafkaProducerService.java` 两个文件。
包含接口定义 KafkaProducerService.Iface，以及服务调用的底层通信细节。
包括客户端的调用逻辑 KafkaProducerService.Client 以及服务端的处理逻辑 KafkaProducerService.Processor。

3.创建一个声明所有 thrift 接口的 maven 项目，取名`thrift-interface`，在 `pom.xml` 文件中添加依赖

```
<dependency>
    <groupId>org.apache.thrift</groupId>
    <artifactId>libthrift</artifactId>
    <version>0.9.3</version>
</dependency>
```

并且将 gen-java 的目录下的文件放到项目中。

4.打包，上传到本地私服 nexus 中。

```
    $ maven package
    $ mvn deploy:deploy-file -DgroupId=com.lfzhu -DartifactId=thrift-interface -Dversion=0.0.1 -Dpackaging=jar -Dfile=target/thrift-interface-0.0.1.jar -DpomFile=pom.xml -Durl=http://host:port/repository/maven-releases -DrepositoryId=nexus
```

#### 定义 Thrift 和 Zookeeper 服务工厂
1.创建 maven 项目，取名`thrift-zookeeper-factory`，在 `pom.xml` 文件中添加依赖
   
```
<!-- thrift -->
<dependency>
    <groupId>org.apache.thrift</groupId>
    <artifactId>libthrift</artifactId>
    <version>0.9.3</version>
</dependency>

<!-- zookeeper -->
<dependency>
    <groupId>org.apache.zookeeper</groupId>
    <artifactId>zookeeper</artifactId>
    <version>3.4.6</version>
</dependency>
<dependency>
    <groupId>org.apache.helix</groupId>
    <artifactId>helix-core</artifactId>
    <version>0.6.4</version>
</dependency>
```

2.定义 Thrift 客户端管理器

```
public class MyTServiceClient extends TServiceClient {

    public MyTServiceClient(TProtocol prot) {
        super(prot);
    }
}
```

3.定义 Thrift 服务端管理器

```
public class ThriftServerManager {

    ExecutorService executor = Executors.newSingleThreadExecutor();

    public static Map<String, TServiceClient> serviceMap = new HashMap<String, TServiceClient>();

    private int servicePort;

    private TProcessor iface;

    public ThriftServerManager(TProcessor iface, int servicePort) {
        this.iface = iface;
        this.servicePort = servicePort;
    }

    public void publishThriftServiceInThreadPool() {
        executor.execute(new Runnable() {
            @Override
            public void run() {
                try {
                    publishThriftService(iface).serve();//注册完服务后，需要启动Tserver
                } catch (TTransportException e) {
                    throw new RuntimeException("Init TTransport error! port is " + servicePort);
                }
            }
        });
    }

    //实现thrift服务注册
    private TServer publishThriftService(TProcessor iface) throws TTransportException {
        TServerTransport transport = new TServerSocket(servicePort);
        TServer server =
            new TThreadPoolServer(new TThreadPoolServer.Args(transport).processor(iface));
        return server;
    }
}
```
4.定义 Zookeeper 客户端管理器

```
public class ZooKeeperClientManager {

    ExecutorService executor = Executors.newSingleThreadExecutor();

    public static Map<String, TServiceClient> serviceMap = new HashMap<String, TServiceClient>();

    private int servicePort;

    private String serviceName;

    private String zookeeperList;

    public ZooKeeperClientManager(String serviceName, String zookeeperList, int servicePort) {
        this.servicePort = servicePort;
        this.serviceName = serviceName;
        this.zookeeperList = zookeeperList;
    }

    public static TServiceClient getRandomService() {
        if (serviceMap.size() < 1) {
            System.out.println("无可供选择的服务！");
            return null;
        }
        for (Map.Entry<String, TServiceClient> entry : serviceMap.entrySet()) {
            System.out.println("可供选择服务:" + entry.getKey());
        }
        int rand = new Random().nextInt(serviceMap.size());
        String[] mkeys = serviceMap.keySet().toArray(new String[serviceMap.size()]);
        System.out.println("当前使用的服务:" + mkeys[rand]);
        return serviceMap.get(mkeys[rand]);
    }

    public void startZooKeeperInThreadPool() {
        executor.execute(new Runnable() {
            @Override
            public void run() {
                startZooKeeper();
            }
        });
    }

    // 注册服务
    private void startZooKeeper() {
        List<String> currChilds = new ArrayList<String>();
        String servicePath = "/" + serviceName;
        ZkClient zkClient = new ZkClient(zookeeperList);
        boolean serviceExists = zkClient.exists(servicePath);
        if (serviceExists) {
            currChilds = zkClient.getChildren(servicePath);
        } else {
            throw new RuntimeException("service not exist!");
        }

        for (String instanceName : currChilds) {
            if (!serviceMap.containsKey(instanceName)) {
                serviceMap.put(instanceName, createService(instanceName));
            }
        }
        // 注册事件监听,动态监控服务增加/删除
        zkClient.subscribeChildChanges(servicePath, new IZkChildListener() {
            @Override
            public void handleChildChange(String parentPath,
                List<String> currentChilds) throws Exception {
                for (String instanceName : currentChilds) {
                    if (!serviceMap.containsKey(instanceName)) {
                        serviceMap.put(instanceName, createService(instanceName));
                        System.out.println(parentPath + "事件触发,增加服务实例" + instanceName);
                    }
                }
                Map<String, TServiceClient> tempMap = new HashMap<String, TServiceClient>();
                tempMap.putAll(serviceMap);
                for (Map.Entry<String, TServiceClient> entry : tempMap.entrySet()) {
                    if (!currentChilds.contains(entry.getKey())) {
                        TServiceClient c = serviceMap.get(entry.getKey());
                        try {
                            c.getInputProtocol().getTransport().close();
                            c.getOutputProtocol().getTransport().close();
                        } catch (Exception e) {
                            e.printStackTrace();
                        }
                        serviceMap.remove(entry.getKey());
                        System.out.println(parentPath + "事件触发,移除服务实例" + entry.getKey());
                    }
                }
            }
        });
    }

    public TServiceClient createService(String serviceInstanceName) {
        return new MyTServiceClient(getTProtocol(serviceInstanceName));
    }

    public TProtocol getTProtocol(String serviceInstanceName) {
        String ip = serviceInstanceName.split("-")[1];
        TSocket transport = new TSocket(ip, servicePort);

        try {
            transport.open();
        } catch (TTransportException ex) {
            throw new RuntimeException("Thrift socket can not open!" + ex.getMessage());
        }
        return new TBinaryProtocol(transport);
    }
}
```

5.定义 Zookeeper 服务端管理器

```
public class ZooKeeperServerManager {

    ExecutorService executor = Executors.newSingleThreadExecutor();

    public static Map<String, TServiceClient> serviceMap = new HashMap<String, TServiceClient>();

    private String serviceName;

    private String zookeeperList;

    public ZooKeeperServerManager(String serviceName, String zookeeperList) {
        this.serviceName = serviceName;
        this.zookeeperList = zookeeperList;
    }

    public void registThriftServiceToZookeeperInThreadPool() {
        executor.execute(new Runnable() {
            @Override
            public void run() {
                registThriftServiceToZookeeper();
            }
        });
    }

    // 注册服务
    private ZkClient registThriftServiceToZookeeper() {
        String servicePath = "/" + serviceName;
        ZkClient zkClient = new ZkClient(zookeeperList);
        boolean rootExists = zkClient.exists(servicePath);
        if (!rootExists) {
            zkClient.createPersistent(servicePath);
        }
        InetAddress addr = null;
        try {
            addr = InetAddress.getLocalHost();
        } catch (UnknownHostException e) {
            e.printStackTrace();
        }
        String ip = addr.getHostAddress().toString();
        String serviceInstance = System.nanoTime() + "-" + ip;
        // 注册当前服务
        zkClient.createEphemeral(servicePath + "/" + serviceInstance);
        System.out.println("提供的服务为：" + servicePath + "/" + serviceInstance);
        return zkClient;
    }

}
```

6.打包，上传到本地私服 nexus 中。

```
    $ maven package
    $ mvn deploy:deploy-file -DgroupId=com.lfzhu -DartifactId=thrift-zookeeper-factory -Dversion=0.0.1 -Dpackaging=jar -Dfile=target/thrift-zookeeper-factory-0.0.1.jar -DpomFile=pom.xml -Durl=http://host:port/repository/maven-releases -DrepositoryId=nexus
```

#### 定义 Kafka 生产日志的微服务
1.创建 Spring boot 项目，取名`kafka-producer-server`，在 `pom.xml` 文件中添加依赖
   
```
<parent>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-parent</artifactId>
    <version>1.3.3.RELEASE</version>
    <relativePath/>
</parent>

<dependencies>
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-web</artifactId>
    </dependency>
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-actuator</artifactId>
    </dependency>

    <!-- thrift -->
    <dependency>
        <groupId>org.apache.thrift</groupId>
        <artifactId>libthrift</artifactId>
        <version>0.9.3</version>
    </dependency>

    <!-- zookeeper -->
    <dependency>
        <groupId>org.apache.zookeeper</groupId>
        <artifactId>zookeeper</artifactId>
        <version>3.4.6</version>
    </dependency>
    <dependency>
        <groupId>org.apache.helix</groupId>
        <artifactId>helix-core</artifactId>
        <version>0.6.4</version>
    </dependency>

    <!-- kafka -->
    <dependency>
        <groupId>org.apache.kafka</groupId>
        <artifactId>kafka_2.10</artifactId>
        <version>0.9.0.1</version>
    </dependency>

    <!-- thrift 接口项目 -->
    <dependency>
        <groupId>com.lfzhu</groupId>
        <artifactId>thrift-interface</artifactId>
        <version>0.0.1</version>
    </dependency>
    
    <!-- thrift zookeeper  服务工厂项目-->
    <dependency>
        <groupId>com.lfzhu</groupId>
        <artifactId>thrift-zookeeper-factory</artifactId>
        <version>0.0.1</version>
    </dependency>
</dependencies>
```

2.在 `application.properties` 文件中添加 zookeeper 和 kafka 的属性配置
```
#zookeeper
zookeeper.service.name=kafka-producer-thrift-service
zookeeper.service.port=7901
zookeeper.server.list=127.0.0.1:2181
#kafka
bootstrap.servers=127.0.0.1:9092
client.id=FasLogProducer
```

3.初始化 Thrift 和 ZooKeeper 服务器端的配置工厂

```
@Configuration
public class ZooKeeperConfigFactory {

    @Value("${zookeeper.service.name}")
    private String serviceName;

    @Value("${zookeeper.service.port}")
    private String servicePort;

    @Value("${zookeeper.server.list}")
    private String zookeeperList;

    @PostConstruct
    public void init() {
        int port = Integer.valueOf(servicePort);
        KafkaProducerService.Processor processor =
            new KafkaProducerService.Processor(new KafkaProducerServiceImpl());
        ThriftServerManager thriftServerManager = new ThriftServerManager(processor, port);
        thriftServerManager.publishThriftServiceInThreadPool();
        
        ZooKeeperServerManager server = new ZooKeeperServerManager(serviceName, zookeeperList);
        server.registThriftServiceToZookeeperInThreadPool();
    }
}
```

- `publishThriftServiceInThreadPool` 的作用是将实现类注册到 thrift 服务器中。注册完服务后，启动 TServer，这一步需要在线程里启动。

- `registThriftServiceToZookeeperInThreadPool` 的作用是使用 zookeeper 进行服务名称注册。这样才能实现负载均衡，让客户端可以根据服务实例列表选择服务来执行。

- 这里只需要注册服务所在服务器的IP即可，因为客户端只要知道IP，也就知道访问那个IP下的该服务。

- 要注意这里使用 zkClient.createEphemeral 建立临时节点，如果这台服务器宕机，这个临时节点是会被清除的，这样客户端在访问时就不会再选择该服务器上的服务。


4.定义 Kafka 生产者回调类

```
class KafkaCallBack implements Callback {

    public Logger logger = LoggerFactory.getLogger(KafkaCallBack.class);


    private Long startTime;
    private Long key;
    private String message;

    public KafkaCallBack(Long startTime, Long key, String message) {
        this.startTime = startTime;
        this.key = key;
        this.message = message;
    }

    public void onCompletion(RecordMetadata metadata, Exception exception) {
        long elapsedTime = System.currentTimeMillis() - startTime;
        if (metadata != null) {
            logger.debug("message(" + key + ", " + message + ") sent to partition(" + metadata.partition()
                    + "), " + "offset(" + metadata.offset() + ") in " + elapsedTime + " ms");
        } else {
            logger.error("produce message failed,cause by [" + exception.getMessage() + "]");
        }
    }
}
```

5.初始化 Kafka 生产者配置工厂

```
@Component
public class KafkaFactory {

    @Value("${bootstrap.servers}")
    private String servers;

    @Value("${client.id}")
    private String clientId;

    private static org.apache.kafka.clients.producer.KafkaProducer producer;

    @PostConstruct
    public void init() {
        initKafkaProducer();
    }

    private void initKafkaProducer() {
        Properties props = new Properties();
        props.put("bootstrap.servers", servers);
        props.put("client.id", clientId);
        props.put("key.serializer", "org.apache.kafka.common.serialization.LongSerializer");
        props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        this.producer = new org.apache.kafka.clients.producer.KafkaProducer<Long, String>(props);
    }

    public static KafkaProducer getProducer() {
        return producer;
    }

}
```

6.定义 Kafka 生产日志的服务类，实现之前通过 Thrift 定义的接口协议

```
public class KafkaProducerServiceImpl implements KafkaProducerService.Iface {

    @Override
    public void sendMessageToKafka(MessageSendBean messageSendBean) {
        String topic = messageSendBean.getTopic();
        String message = messageSendBean.getMessage();
        org.apache.kafka.clients.producer.KafkaProducer producer = KafkaFactory.getProducer();
        Long startTime = System.currentTimeMillis();
        producer.send(new ProducerRecord<Long, String>(topic, startTime, message),new KafkaCallBack(startTime, startTime, message));
    }

}
```

7.启动 Spring boot 应用

```
@EnableAutoConfiguration
@ComponentScan("com.lfzhu.*")
@ServletComponentScan
public class MyApplication {

    public static void main(String[] args) {
        SpringApplication.run(MyApplication.class, args);
    }
}
```

我们可以将该微服务部署到多台服务器中，实现负载均衡。

#### 主服务中通过 Thrift 通信协议调用微服务，实现日志存储
1.在 `pom.xml` 文件中添加依赖

```
<!-- thrift 接口项目 -->
<dependency>
    <groupId>com.lfzhu</groupId>
    <artifactId>thrift-interface</artifactId>
    <version>0.0.1</version>
</dependency>

<!-- thrift zookeeper  服务工厂项目-->
<dependency>
    <groupId>com.lfzhu</groupId>
    <artifactId>thrift-zookeeper-factory</artifactId>
    <version>0.0.1</version>
</dependency>
```

2.重写 `ZooKeeperClientManager` 类里面的 `createService()` 方法，将真实的 TServiceClient 注册进来

```
public class MyZookeeperClientManager extends ZooKeeperClientManager {


    public MyZookeeperClientManager(String serviceName, String zookeeperList, int servicePort) {
        super(serviceName, zookeeperList, servicePort);
    }

    @Override
    public TServiceClient createService(String serviceInstanceName) {
        return new KafkaProducerService.Client(this.getTProtocol(serviceInstanceName));
    }

}
```

3.初始化 ZooKeeper 客户端的配置工厂，并且注册事件监听

```
public class ZooKeeperConfigFactory {

    @Bean
    public Boolean startZooKeeperInThreadPool() {
        String serviceName = String.valueOf(System.getenv("serviceName"));//参数通过环境变量注入进来
        String servicePort = String.valueOf(System.getenv("servicePort"));
        String zookeeperList = String.valueOf(System.getenv("zookeeperList"));
        int port = Integer.valueOf(servicePort);
        MyZooKeeperClientManager client = new MyZooKeeperClientManager(serviceName, zookeeperList, port);
        client.startZooKeeperInThreadPool();
        return Boolean.TRUE;
    }
}
```

- `startZooKeeperInThreadPool` 的作用是注册事件监听，客户端需要能及时的监听服务列表的变化并作出负载均衡。


4.在 `applicationContext.xml` 文件中初始化 `ZooKeeperConfigFactory`

```
<bean id="zooKeeperConfigFactory" class="com.amarsoft.fas.kafka.service.ZooKeeperConfigFactory"/>
```

5.封装存储日志的接口

```
public interface KafkaProduceService {

    void sendMessageToKafka(String topic, String message);
}
```


6.实现存储日志的接口

```
@Service
public class KafkaProduceServiceImpl implements KafkaProduceService {

    private Logger logger = LoggerFactory.getLogger(KafkaProduceServiceImpl.class);

    @Override
    public void sendMessageToKafka(String topic, String message) {
        MessageSendBean messageSendBean = new MessageSendBean();
        messageSendBean.setTopic(topic);
        messageSendBean.setMessage(message);
        
        String serviceName = String.valueOf(System.getenv("serviceName"));//参数通过环境变量注入进来
        String servicePort = String.valueOf(System.getenv("servicePort"));
        
        TServiceClient randomServiceClient = MyZooKeeperClientManager.getRandomService();
        if (randomServiceClient == null) {
            logger.error("Remote kafka produce service is null, service name is " + serviceName + ",port is " + servicePort);
            return;
        }

        KafkaProducerService.Client svr = (KafkaProducerService.Client) randomServiceClient;
        try {
            svr.sendMessageToKafka(messageSendBean);//RPC 调用微服务接口
        } catch (TException ex) {
            logger.error("Send message to kafka failed, service name is " + serviceName + ",port is "
                    + servicePort + ",error message is " + ex.getMessage() + ".");
            return;
        }
    }
}
```

- 这里我们使用最简单的随机获取服务来作为负载均衡的一种方式。

## 总结
至此，我们实现了一个简单的微服务案例。

主服务采用 Thrift 通信协议，通过 Zookeeper 进行服务治理，随即获取一个微服务对象，远程调用该微服务的存储日志的接口。从而实现 Kafka 生产者模式记录日志的功能。

# 参考
[Building Apache Thrift on CentOS](https://thrift.apache.org/docs/install/centos)

[Building Apache Thrift on CentOS (简书)](http://www.jianshu.com/p/08c5d24656ae)

[Thrift入门初探](http://www.cnblogs.com/fingerboy/p/6424248.html)

[Writing a .thrift file](http://thrift-tutorial.readthedocs.io/en/latest/thrift-file.html)

[基于Zookeeper的服务注册与发现 ](https://tech.imdada.cn/2015/12/03/service-registry-and-discovery-with-zk/)

[Spring cloud 7day simple](https://gitee.com/zhou666/spring-cloud-7simple)

[Spring cloud 7day simple 说明](http://www.cnblogs.com/skyblog/p/5535418.html)

[Apache Helix简介](http://blog.csdn.net/oopsoom/article/details/47416575)

[Kafka快速入门](http://colobu.com/2014/08/06/kafka-quickstart/)

[Kafka 0.9.0 Documentation](http://kafka.apache.org/090/documentation.html#quickstart)
